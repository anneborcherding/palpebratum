{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fuzzer Evaluation\n",
    "\n",
    "This notebook helps to preprocess, visualize, and evaluate the coverage achieved by the different fuzzers considered in our paper. All fuzzers use the same fuzzer implementation (based on LibAFL), but receive different feedback on the interestingness of a given test case.\n",
    "\n",
    "* `RANDOM`: This fuzzer receives random feedback on whether a test case is interesting or not. Each test case has a probability of 0.5 to be considered interesting.\n",
    "* `BLACKBOX`: This fuzzer receives no information on the interestingness of a test cases and considers all test cases as interesting (and thus adds all test cases to the corpus).\n",
    "* `PALPEBRATUM_AE`: This fuzzer uses our newly presented, HMM-based approach to the interestingness assessment. It uses an HMM with 51 nodes and uses an autoencoder to preprocess the network traffic.\n",
    "* `PALPEBRATUM_CAPC`: This fuzzer uses our newly presented, HMM-based approach to the interestingness assessment. It uses an HMM with 51 nodes and uses a convolutional autoencoder to preprocess the network traffic.\n",
    "\n",
    "In addition to these blackbox fuzzers, we consider the graybox fuzzer [AFLnwe](https://github.com/thuanpv/aflnwe), which uses graybox coverage information to decide on the interestingness of a test case.\n"
   ],
   "id": "d8fe2e2aa1af7373"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# names of the fuzzers used in the .csv file\n",
    "fuzzers = [\"ae\", \"capc\", \"blackbox\", \"random\", \"aflnwe\"]\n",
    "\n",
    "# location of the .csv file\n",
    "csv_path = '../evaluation_data/fuzzers/coverage.csv'"
   ],
   "id": "e22a147fda68af31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Raw Data\n",
    "\n",
    "First, let's have a quick look at the coverage data that we collected from the different fuzzers. \n",
    "\n",
    "We run each fuzzer 30 times and collected the coverage that the generated test cases achieve for each run. We collected the basic block coverage (absolute and relative) and the line coverage (also absolute and relative). The column `cov_type` indicates which kind of coverage is given in the specific row (denoted by \"b_abs\", \"b_per\", \"l_abs\", and \"l_per\", respectively). Note that we calculated the coverage of **all** generated test cases, not only those test cases in the corpus to be sure to measure the total coverage achieved by each fuzzer. `subject` denotes the target of the test, which is ProFTP for all of our runs, and `run` includes the number of the run (1 to 30 for each fuzzer).\n"
   ],
   "id": "331e234de3077b33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select one of the fuzzers and coverage type to check the data for\n",
    "fuzzer = \"blackbox\" # choose one of \"ae\" | \"capc\" | \"blackbox\" | \"random\" | \"aflnwe\"\n",
    "cov_type = \"b_abs\" # choose one of \"b_abs\" | \"b_per\" | \"l_abs\" | \"l_per\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.sort_values(by='time')\n",
    "df_fuzzer = df[df['fuzzer'] == fuzzer]\n",
    "df_fuzzer = df_fuzzer[df_fuzzer['cov_type'] == cov_type]\n",
    "df_fuzzer"
   ],
   "id": "b3d09abb3639c517",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graphical Representation\n",
    "\n",
    "Let's make this raw data more colorful and nicer to look at.\n",
    "\n",
    "We start by plotting the coverage over time of each run for each fuzzer to get a general understanding on how the fuzzing runs went and how the performance is distributed. Note that we choose different intervals for the y-axis for the blackbox fuzzers and the graybox fuzzer AFLnwe, as the latter generally achieves higher coverage (as expected).\n",
    "\n",
    "This representation is indeed colorful, but also a little bit messy. If you want a cleaner visualization, check the cell below."
   ],
   "id": "5fcd1301f9d0fc27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# choose the coverage type you would like to look at (\"b_abs\" | \"b_per\" | \"l_abs\" | \"l_per\")\n",
    "cov_type = 'b_abs'\n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize=(15,5))\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[0].set_ylabel(f'Coverage ({cov_type})')\n",
    "\n",
    "for i, fuzzer in enumerate(fuzzers):\n",
    "    dff = df[(df['fuzzer'] == fuzzer) & (df['cov_type'] == cov_type)]\n",
    "    for key, group in dff.groupby(\"run\"):\n",
    "        time_shifted = sorted(group['time'] - group['time'].iloc[0])\n",
    "        ax[i].plot(time_shifted, group['cov'])\n",
    "    ax[i].set_title(fuzzer)\n",
    "    if fuzzer == \"aflnwe\":\n",
    "        # set different limits for aflnwe for visualization purposes    \n",
    "        ax[i].set_ylim([3200, 5650])\n",
    "    else:\n",
    "        ax[i].set_ylim([3200, 4490])\n",
    "    ax[i].set_xlabel('Time in seconds')\n",
    "\n",
    "plt.subplots_adjust(hspace=2)\n",
    "plt.show()"
   ],
   "id": "e7b7aa01259fef3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the next plot, we aggregate our coverage data to clean up the visualization. To this end, we calculate the mean coverage achieved by each fuzzer over time and plot this. To be able to calculate a meaningful mean value, we first interpolate the coverage values to align them on a fixed grid of times.",
   "id": "8df806d20feb525a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# choose the coverage type you would like to look at (\"b_abs\" | \"b_per\" | \"l_abs\" | \"l_per\")\n",
    "cov_type = 'b_abs'\n",
    "# choose whether to include AFLnwe\n",
    "# if it is not included, more details of the blackbox fuzzers are visible\n",
    "include_aflnwe = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "mean_data = {}\n",
    "\n",
    "for fuzzer in fuzzers:\n",
    "    if not include_aflnwe and fuzzer == \"aflnwe\":\n",
    "        continue\n",
    "        \n",
    "    dff = df[(df['fuzzer'] == fuzzer) & (df['cov_type'] == cov_type)]\n",
    "    \n",
    "    # Common time grid\n",
    "    all_times = np.linspace(0, 86400, 500)  \n",
    "    cov_values = []\n",
    "\n",
    "    # Interpolate each run's coverage values to the time grid\n",
    "    for key, group in dff.groupby(\"run\"):\n",
    "        time_shifted = sorted(group['time'] - group['time'].min())\n",
    "        interpolated_cov = np.interp(all_times, time_shifted, group['cov'])\n",
    "        cov_values.append(interpolated_cov)\n",
    "    \n",
    "    # Calculate the mean coverage values and standard deviation at each time point\n",
    "    mean_cov = np.mean(cov_values, axis=0)\n",
    "    mean_data[fuzzer] = (all_times, mean_cov)\n",
    "    std_err = stats.sem(cov_values, axis=0, nan_policy=\"omit\")\n",
    "    confidence_interval = 1.96 * std_err\n",
    "\n",
    "    ax.plot(all_times, mean_cov, label=fuzzer)\n",
    "    ax.fill_between(all_times, mean_cov - confidence_interval, mean_cov + confidence_interval, alpha=0.2)\n",
    "\n",
    "ax.set_title(\"Mean Coverage Over Time\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(f\"Coverage ({cov_type})\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "db40183efdca0b0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Numbers\n",
    "\n",
    "We can also calculate some metrics based on the data that we collected. The following cell calculates and shows the total coverage (absolute and relative), the coverage achieved by the test cases excluding the inital seeds, the number of generated test cases, and the average coverage per test case."
   ],
   "id": "97e1e79a765d2e11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = []\n",
    "\n",
    "for i, fuzzer in enumerate(fuzzers):\n",
    "    dff = df[(df['fuzzer'] == fuzzer) & (df['cov_type'] == 'b_abs')]\n",
    "    total_tcs = 0\n",
    "    total_cov = 0\n",
    "    total_cov_delta = 0\n",
    "    num_runs = 0\n",
    "\n",
    "    for key, group in dff.groupby(\"run\"):\n",
    "        total_tcs += (len(group) - 13)\n",
    "        total_cov += group[\"cov\"].max()\n",
    "        total_cov_delta += (group[\"cov\"].max() - group[\"cov\"].iloc[12])\n",
    "        num_runs += 1\n",
    "\n",
    "    total_tcs /= num_runs\n",
    "    total_cov /= num_runs    \n",
    "    total_cov_delta /= num_runs    \n",
    "\n",
    "    results.append({\n",
    "        \"Fuzzer\": fuzzer,\n",
    "        \"Total Coverage\": round(total_cov, 2),\n",
    "        \"Relative Coverage (%)\": round(total_cov * 0.003633, 2),\n",
    "        \"Coverage Excluding Seeds\": round(total_cov_delta, 2),\n",
    "        \"Number of Test Cases\": round(total_tcs, 2),\n",
    "        \"Coverage per Test Case\": round(total_cov_delta / total_tcs, 2)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)\n"
   ],
   "id": "a28d6f6926ca146e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
